{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f720b9-2fe5-481d-8e62-b50ddd112ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d2beb9-f422-48ec-9601-97efa5113125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in ./path/to/venv/lib/python3.13/site-packages (37.8.0)\n",
      "Requirement already satisfied: tzdata in ./path/to/venv/lib/python3.13/site-packages (from Faker) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af49c69-5a44-4207-b338-be1be73082f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\n",
      "  Using cached faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in /opt/homebrew/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages (from Faker) (2025.2)\n",
      "Using cached faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: Faker\n",
      "Successfully installed Faker-37.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0da9494-6ff1-4b89-a898-7cba6c35d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd2cf24-cce3-4354-8aca-585ff8b26dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset successfully created with Indian railway data!\n"
     ]
    }
   ],
   "source": [
    "fake = Faker('en_IN')  # Use Indian locale for Indian names\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Indian Railway Stations\n",
    "indian_stations = [\n",
    "    (\"New Delhi\", \"Delhi\"), (\"Mumbai Central\", \"Maharashtra\"), (\"Chennai Central\", \"Tamil Nadu\"),\n",
    "    (\"Howrah Junction\", \"West Bengal\"), (\"Bangalore City\", \"Karnataka\"), (\"Secunderabad\", \"Telangana\"),\n",
    "    (\"Ahmedabad\", \"Gujarat\"), (\"Pune Junction\", \"Maharashtra\"), (\"Kolkata Shalimar\", \"West Bengal\"),\n",
    "    (\"Lucknow Charbagh\", \"Uttar Pradesh\"), (\"Patna Junction\", \"Bihar\"), (\"Jaipur Junction\", \"Rajasthan\"),\n",
    "    (\"Bhopal Junction\", \"Madhya Pradesh\"), (\"Thiruvananthapuram\", \"Kerala\"), (\"Guwahati\", \"Assam\"),\n",
    "    (\"Visakhapatnam\", \"Andhra Pradesh\"), (\"Nagpur\", \"Maharashtra\"), (\"Coimbatore\", \"Tamil Nadu\"),\n",
    "    (\"Varanasi Junction\", \"Uttar Pradesh\"), (\"Madurai Junction\", \"Tamil Nadu\")\n",
    "]\n",
    "\n",
    "# Indian Train Names\n",
    "indian_trains = [\n",
    "    \"Rajdhani Express\", \"Shatabdi Express\", \"Duronto Express\", \"Gatiman Express\",\n",
    "    \"Tejas Express\", \"Garib Rath Express\", \"Vande Bharat Express\", \"Maharaja Express\",\n",
    "    \"Deccan Queen\", \"Humsafar Express\", \"Sampark Kranti Express\", \"Jan Shatabdi Express\"\n",
    "]\n",
    "\n",
    "# Generating Data\n",
    "num_trains = 50\n",
    "num_stations = len(indian_stations)\n",
    "num_passengers = 5000\n",
    "num_bookings = 10000\n",
    "num_tickets = 20000\n",
    "\n",
    "# 1️⃣ Generate Trains Data\n",
    "train_data = []\n",
    "for i in range(1, num_trains + 1):\n",
    "    train_data.append((i, random.choice(indian_trains), random.choice([\"Express\", \"Superfast\", \"Local\"]), \n",
    "                       random.randint(10, 20), random.randint(300, 1000)))\n",
    "\n",
    "# 2️⃣ Generate Stations Data\n",
    "station_data = []\n",
    "for i, (station, state) in enumerate(indian_stations, start=1):\n",
    "    station_data.append((i, station, state))\n",
    "\n",
    "# 3️⃣ Generate Passengers Data with Indian Names\n",
    "passenger_data = []\n",
    "for i in range(1, num_passengers + 1):\n",
    "    phone_number = f\"{random.randint(7000000000, 9999999999)}\"  # Ensure 10-digit phone number\n",
    "    passenger_data.append((i, fake.name(), random.randint(10, 80), random.choice([\"Male\", \"Female\", \"Other\"]), \n",
    "                           phone_number))\n",
    "\n",
    "# 4️⃣ Generate Bookings Data\n",
    "booking_data = []\n",
    "for i in range(1, num_bookings + 1):\n",
    "    booking_data.append((i, random.randint(1, num_passengers), random.randint(1, num_trains), \n",
    "                         fake.date_this_year(), random.randint(1, num_stations), random.randint(1, num_stations),\n",
    "                         random.choice([\"Confirmed\", \"Waitlisted\", \"Cancelled\"])))\n",
    "\n",
    "# 5️⃣ Generate Tickets Data\n",
    "ticket_data = []\n",
    "for i in range(1, num_tickets + 1):\n",
    "    ticket_data.append((i, random.randint(1, num_bookings), f\"S{random.randint(1, 50)}-{random.randint(1, 6)}\", \n",
    "                        f\"C{random.randint(1, 10)}\", random.choice([\"Sleeper\", \"AC\", \"General\"]), \n",
    "                        round(random.uniform(50, 500), 2)))\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_trains = pd.DataFrame(train_data, columns=[\"train_id\", \"train_name\", \"train_type\", \"total_coaches\", \"seat_capacity\"])\n",
    "df_stations = pd.DataFrame(station_data, columns=[\"station_id\", \"station_name\", \"state\"])\n",
    "df_passengers = pd.DataFrame(passenger_data, columns=[\"passenger_id\", \"full_name\", \"age\", \"gender\", \"phone_number\"])\n",
    "df_bookings = pd.DataFrame(booking_data, columns=[\"booking_id\", \"passenger_id\", \"train_id\", \"journey_date\", \n",
    "                                                  \"source_station_id\", \"destination_station_id\", \"booking_status\"])\n",
    "df_tickets = pd.DataFrame(ticket_data, columns=[\"ticket_id\", \"booking_id\", \"seat_number\", \"coach_number\", \"class_type\", \"fare_amount\"])\n",
    "\n",
    "folder = \"Indian Railways\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "df_trains.to_csv(os.path.join(folder, \"trains.csv\"), index=False)\n",
    "df_stations.to_csv(os.path.join(folder, \"stations.csv\"), index=False)\n",
    "df_passengers.to_csv(os.path.join(folder, \"passengers.csv\"), index=False)\n",
    "df_bookings.to_csv(os.path.join(folder, \"bookings.csv\"), index=False)\n",
    "df_tickets.to_csv(os.path.join(folder, \"tickets.csv\"), index=False)\n",
    "\n",
    "\n",
    "print(\"✅ Dataset successfully created with Indian railway data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa59c1a-4f70-49d1-b9a7-0f329fb03ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
